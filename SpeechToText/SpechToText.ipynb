{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# speech recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python 2.x program to transcribe an Audio file \n",
    "import speech_recognition as sr\n",
    "sr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio source is .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AudioData' object has no attribute 'getframes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-500fe2c0c44c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"audio.frame_data = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"audio.duration = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AudioData' object has no attribute 'getframes'"
     ]
    }
   ],
   "source": [
    "#AUDIO_FILE = (\"egotistical.wav\") \n",
    "#AUDIO_FILE = (\"OSR_us_000_0010_8k.wav\") \n",
    "AUDIO_FILE = (\"everything_all_right.wav\") \n",
    "\n",
    "# use the audio file as the audio source \n",
    "  \n",
    "r = sr.Recognizer() \n",
    "  \n",
    "with sr.AudioFile(AUDIO_FILE) as source: \n",
    "    #reads the audio file. Here we use record instead of \n",
    "    #listen \n",
    "    audio = r.record(source)   \n",
    "    \n",
    "    print(\"audio.frame_data = \", audio.getframes())\n",
    "    print(\"audio.duration = \", audio.sample_rate)\n",
    "  \n",
    "    \n",
    "    \n",
    "  \n",
    "try: \n",
    "    print(\"The audio file contains: \" + r.recognize_google(audio)) \n",
    "  \n",
    "except:\n",
    "    pass\n",
    "\n",
    "#except sr.UnknownValueError: \n",
    "    #print(\"Google Speech Recognition could not understand audio\") \n",
    "  \n",
    "#except sr.RequestError as e: \n",
    "    #print(\"Could not request results from Google Speech  \n",
    "              #Recognition service; {0}\".format(e)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Source is Microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please say something: \n",
      "Google thinks you Said: Amazon\n",
      "r.energy_threshold =  246.03158488060004\n",
      "Help on method recognize_google in module speech_recognition:\n",
      "\n",
      "recognize_google(audio_data, key=None, language='en-US', show_all=False) method of speech_recognition.Recognizer instance\n",
      "    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Google Speech Recognition API.\n",
      "    \n",
      "    The Google Speech Recognition API key is specified by ``key``. If not specified, it uses a generic key that works out of the box. This should generally be used for personal or testing purposes only, as it **may be revoked by Google at any time**.\n",
      "    \n",
      "    To obtain your own API key, simply following the steps on the `API Keys <http://www.chromium.org/developers/how-tos/api-keys>`__ page at the Chromium Developers site. In the Google Developers Console, Google Speech Recognition is listed as \"Speech API\".\n",
      "    \n",
      "    The recognition language is determined by ``language``, an RFC5646 language tag like ``\"en-US\"`` (US English) or ``\"fr-FR\"`` (International French), defaulting to US English. A list of supported language tags can be found in this `StackOverflow answer <http://stackoverflow.com/a/14302134>`__.\n",
      "    \n",
      "    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the raw API response as a JSON dictionary.\n",
      "    \n",
      "    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use the audio file as the audio source \n",
    "  \n",
    "r = sr.Recognizer() \n",
    "  \n",
    "with sr.Microphone() as source: \n",
    "    #reads the audio file. Here we use record instead of \n",
    "    #listen \n",
    "    print(\"Please say something: \")\n",
    "    #audio = r.listen(source)  \n",
    "    \n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.record(source, offset=0, duration=2)\n",
    "    \n",
    "    #print(audio.get_wav_data())\n",
    "    \n",
    "    \n",
    "  \n",
    "try: \n",
    "    #print(\"Google thinks you Said: \" + r.recognize_google(audio)) \n",
    "    print(\"Google thinks you Said: \" + r.recognize_google(audio, language=\"mr-IN\"))  #Hindi\n",
    "    #print(\"Google thinks you Said: \" + r.recognize_google(audio, language=\"ur\"))  #Urdu\n",
    "    #print(\"Google thinks you Said: \" + r.recognize_google(audio, language=\"mr-IN\"))  #Marathi\n",
    "\n",
    "    #print(\"Google thinks you Said: \" + r.recognize_wit(audio)) \n",
    "    #print(\"audio = \", audio)\n",
    "    \n",
    "    \n",
    "    print(\"r.energy_threshold = \", r.energy_threshold)\n",
    "    print(help(r.recognize_google))\n",
    "    #print(r.adjust_for_ambient_noise(source,duration=1))\n",
    "   \n",
    "    \n",
    "except:\n",
    "    \n",
    "    print(\"Some Error occured\")\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "except sr.UnknownValueError: \n",
    "    print(\"Google Speech Recognition could not understand audio\") \n",
    "  \n",
    "except sr.RequestError as e: \n",
    "    print(\"Could not request results from Google Speech  \n",
    "              Recognition service; {0}\".format(e)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording a .wav Audio file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-5a9fc4f6a257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mas_ints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_ints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#I believe the WAVE module does not support recording, just processing existing files. You might want to look at PyAudio for actually recording. WAV is about the world's simplest file format. In paInt16 you just get a signed integer representing a level, and closer to 0 is quieter. I can't remember if WAV files are high byte first or low byte, but something like this ought to work (sorry, I'm not really a python programmer:\n",
    "\n",
    "from array import array\n",
    "\n",
    "# you'll probably want to experiment on threshold\n",
    "# depends how noisy the signal\n",
    "threshold = 10 \n",
    "max_value = 0\n",
    "\n",
    "as_ints = array('h', data)\n",
    "max_value = max(as_ints)\n",
    "if max_value > threshold:\n",
    "    # not silence\n",
    "    pass\n",
    "\n",
    "    \n",
    "#PyAudio code for recording kept for reference:\n",
    "\n",
    "import pyaudio\n",
    "import sys\n",
    "\n",
    "chunk = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS, \n",
    "                rate=RATE, \n",
    "                input=True,\n",
    "                output=True,\n",
    "                frames_per_buffer=chunk)\n",
    "\n",
    "print(\"* recording\")\n",
    "for i in range(0, 44100 / chunk * RECORD_SECONDS):\n",
    "    data = stream.read(chunk)\n",
    "    # check for silence here by comparing the level with 0 (or some threshold) for \n",
    "    # the contents of data.\n",
    "    # then write data or not to a file\n",
    "\n",
    "print(\"* done\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
